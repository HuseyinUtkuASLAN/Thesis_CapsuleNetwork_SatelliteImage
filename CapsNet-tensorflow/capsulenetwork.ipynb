{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CapsNet\n",
    "\n",
    "This is the core algorithm of this thesis. It is based on [Dynamic Routing Between Capsules](https://arxiv.org/abs/1710.09829) paper by Sara Sabour, Nicholas Frosst and Geoffrey E. Hinton.\n",
    "\n",
    "I added few changes to [handson-ml](https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb)'s implementation. \n",
    "\n",
    "There is one big change from the original algorithm and it is primary casules' filter sizes. First 2 convolution layers has filter size of 9. In this thesis, we used a sattelite image and cut the picture with respect to coordinate system that is given. In our tests, 2 different image size and channel types are used. Sizes are 32x32 and 9x9. For 9x9 images, if we use filter size of 9, we got negative filter size thus for 9x9 images, filter size is droped to 3x3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# np.random.seed(42)\n",
    "# tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train =  get_data_set(\"train\",input_path = \"../input/data_9x9_12band/\")\n",
    "x_test,y_test = get_data_set(\"test\",input_path = \"../input/data_9x9_12band/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 9, 9, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, x_train.shape[1], x_train.shape[2], x_train.shape[3]], dtype=tf.float32, name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'X:0' shape=(?, 9, 9, 12) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primary Capsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size_conv1 = 3\n",
    "kernel_size_conv2 = 3\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 2\n",
    "img_size = x_test.shape[1]\n",
    "img_size = int(((img_size - kernel_size_conv1) / stride_conv1) + 1)\n",
    "img_size = int(((img_size - kernel_size_conv2) / stride_conv2) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps * img_size * img_size # * band_size\n",
    "caps1_n_dims = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", filters = 256,\n",
    "                        kernel_size = kernel_size_conv1, strides = stride_conv1,\n",
    "                        padding = \"valid\",activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv1/Relu:0' shape=(?, 7, 7, 256) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", filters = caps1_n_maps * caps1_n_dims,\n",
    "                        kernel_size = kernel_size_conv2, strides = stride_conv2,\n",
    "                        padding = \"valid\",activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2/Relu:0' shape=(?, 3, 3, 256) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_raw:0' shape=(?, 288, 8) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps1_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-fc0e932a5d7c>:5: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_output/mul:0' shape=(?, 288, 8) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15\n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\") \n",
    "caps1_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape = np.unique(y_train).shape[0]\n",
    "caps2_n_caps = output_shape\n",
    "caps2_n_dims = 16\n",
    "type(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'W_tiled:0' shape=(?, 288, 4, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_output_tiled:0' shape=(?, 288, 4, 8, 1) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps1_output_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_predicted:0' shape=(?, 288, 4, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routing by agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'raw_weights:0' shape=(?, 288, 4, 1, 1) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")\n",
    "raw_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-86a489ae595f>:1: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_1/mul:0' shape=(?, 1, 4, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_round_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_weights_round_2 = tf.add(raw_weights, agreement,\n",
    "                             name=\"raw_weights_round_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output = caps2_output_round_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 4, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimated Class Probabilities (Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_proba_1:0' shape=(?, 1, 1) dtype=int64>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "y_proba_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_pred:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 4, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'T:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tf.one_hot(y, depth=output_shape, name=\"T\")\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'present_error:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, output_shape),\n",
    "                           name=\"present_error\")\n",
    "present_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, output_shape),\n",
    "                          name=\"absent_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'L:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'margin_loss:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "margin_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mask_with_labels:0' shape=() dtype=bool>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")\n",
    "mask_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'reconstruction_targets/Merge:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "reconstruction_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'reconstruction_mask:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=output_shape,\n",
    "                                 name=\"reconstruction_mask\")\n",
    "reconstruction_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_masked = tf.multiply(\n",
    "    caps2_output, reconstruction_mask_reshaped,\n",
    "    name=\"caps2_output_masked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_masked:0' shape=(?, 1, 4, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_input:0' shape=(?, 64) dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")\n",
    "decoder_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = x_train.shape[1] * x_train.shape[2] * x_train.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size :  404\n",
      "validation set size :  793\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 150\n",
    "batch_size = 50\n",
    "restore_checkpoint = True\n",
    "num_train_examples = x_train.shape[0]\n",
    "num_test_examples = x_test.shape[0]\n",
    "n_iterations_per_epoch = num_train_examples // batch_size\n",
    "n_iterations_validation = num_test_examples // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "\n",
    "print(\"training set size : \", num_train_examples)\n",
    "print(\"validation set size : \", num_test_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X,Y):\n",
    "    X_per = []\n",
    "    Y_per = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    for i in permutation:\n",
    "        X_per.append(X[i])\n",
    "        Y_per.append(Y[i])\n",
    "        \n",
    "    return np.array(X_per),np.array(Y_per)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 79.8667%  Loss: 797.026978 (improved)\n",
      "Epoch: 2  Val accuracy: 66.2667%  Loss: 797.120361\n",
      "Epoch: 3  Val accuracy: 77.2000%  Loss: 796.492188 (improved)\n",
      "Epoch: 4  Val accuracy: 87.7333%  Loss: 795.602783 (improved)\n",
      "Epoch: 5  Val accuracy: 86.1333%  Loss: 799.718018\n",
      "Epoch: 6  Val accuracy: 82.8000%  Loss: 799.762451\n",
      "Epoch: 7  Val accuracy: 82.2667%  Loss: 798.441406\n",
      "Epoch: 8  Val accuracy: 84.9333%  Loss: 799.011841\n",
      "Epoch: 9  Val accuracy: 88.1333%  Loss: 798.512329\n",
      "Epoch: 10  Val accuracy: 83.3333%  Loss: 797.076111\n",
      "Epoch: 11  Val accuracy: 87.4667%  Loss: 801.982239\n",
      "Epoch: 12  Val accuracy: 87.4667%  Loss: 798.559937\n",
      "Epoch: 13  Val accuracy: 87.3333%  Loss: 799.420898\n",
      "Epoch: 14  Val accuracy: 87.3333%  Loss: 797.636658\n",
      "Epoch: 15  Val accuracy: 86.6667%  Loss: 801.326294\n",
      "Epoch: 16  Val accuracy: 88.9333%  Loss: 795.226685 (improved)\n",
      "Epoch: 17  Val accuracy: 86.5333%  Loss: 800.228577\n",
      "Epoch: 18  Val accuracy: 86.4000%  Loss: 801.871826\n",
      "Epoch: 19  Val accuracy: 88.9333%  Loss: 801.169189\n",
      "Epoch: 20  Val accuracy: 89.0667%  Loss: 797.905823\n",
      "Epoch: 21  Val accuracy: 89.4667%  Loss: 796.084167\n",
      "Epoch: 22  Val accuracy: 89.2000%  Loss: 800.890381\n",
      "Epoch: 23  Val accuracy: 88.0000%  Loss: 798.740845\n",
      "Epoch: 24  Val accuracy: 90.0000%  Loss: 800.880310\n",
      "Epoch: 25  Val accuracy: 86.9333%  Loss: 796.052307\n",
      "Epoch: 26  Val accuracy: 86.0000%  Loss: 797.987305\n",
      "Epoch: 27  Val accuracy: 86.9333%  Loss: 803.277527\n",
      "Epoch: 28  Val accuracy: 87.6000%  Loss: 797.003479\n",
      "Epoch: 29  Val accuracy: 85.8667%  Loss: 799.124817\n",
      "Epoch: 30  Val accuracy: 88.6667%  Loss: 802.039795\n",
      "Epoch: 31  Val accuracy: 88.0000%  Loss: 793.596924 (improved)\n",
      "Epoch: 32  Val accuracy: 88.4000%  Loss: 799.433655\n",
      "Epoch: 33  Val accuracy: 88.2667%  Loss: 800.120239\n",
      "Epoch: 34  Val accuracy: 89.0667%  Loss: 797.620300\n",
      "Epoch: 35  Val accuracy: 87.2000%  Loss: 798.058655\n",
      "Epoch: 36  Val accuracy: 88.6667%  Loss: 798.696045\n",
      "Epoch: 37  Val accuracy: 87.7333%  Loss: 802.000244\n",
      "Epoch: 38  Val accuracy: 85.3333%  Loss: 796.376038\n",
      "Epoch: 39  Val accuracy: 89.3333%  Loss: 797.502991\n",
      "Epoch: 40  Val accuracy: 88.0000%  Loss: 801.465576\n",
      "Epoch: 41  Val accuracy: 88.6667%  Loss: 798.108337\n",
      "Epoch: 42  Val accuracy: 87.8667%  Loss: 800.280273\n",
      "Epoch: 43  Val accuracy: 88.8000%  Loss: 798.536255\n",
      "Epoch: 44  Val accuracy: 88.0000%  Loss: 798.130432\n",
      "Epoch: 45  Val accuracy: 88.6667%  Loss: 798.745850\n",
      "Epoch: 46  Val accuracy: 88.8000%  Loss: 798.328857\n",
      "Epoch: 47  Val accuracy: 89.3333%  Loss: 797.896362\n",
      "Epoch: 48  Val accuracy: 89.3333%  Loss: 800.636108\n",
      "Epoch: 49  Val accuracy: 88.4000%  Loss: 798.943970\n",
      "Epoch: 50  Val accuracy: 89.4667%  Loss: 797.930908\n",
      "Epoch: 51  Val accuracy: 88.0000%  Loss: 801.422241\n",
      "Epoch: 52  Val accuracy: 88.9333%  Loss: 797.114319\n",
      "Epoch: 53  Val accuracy: 86.9333%  Loss: 801.484985\n",
      "Epoch: 54  Val accuracy: 87.7333%  Loss: 797.520508\n",
      "Epoch: 55  Val accuracy: 88.0000%  Loss: 798.829041\n",
      "Epoch: 56  Val accuracy: 88.5333%  Loss: 796.989807\n",
      "Epoch: 57  Val accuracy: 88.9333%  Loss: 796.684143\n",
      "Epoch: 58  Val accuracy: 88.9333%  Loss: 800.922546\n",
      "Epoch: 59  Val accuracy: 87.0667%  Loss: 796.227600\n",
      "Epoch: 60  Val accuracy: 88.5333%  Loss: 796.561340\n",
      "Epoch: 61  Val accuracy: 89.2000%  Loss: 795.978149\n",
      "Epoch: 62  Val accuracy: 88.9333%  Loss: 798.382690\n",
      "Epoch: 63  Val accuracy: 89.2000%  Loss: 800.242371\n",
      "Epoch: 64  Val accuracy: 89.7333%  Loss: 800.747437\n",
      "Epoch: 65  Val accuracy: 89.2000%  Loss: 797.915222\n",
      "Epoch: 66  Val accuracy: 89.3333%  Loss: 799.053772\n",
      "Epoch: 67  Val accuracy: 88.8000%  Loss: 799.401672\n",
      "Epoch: 68  Val accuracy: 89.0667%  Loss: 799.593079\n",
      "Epoch: 69  Val accuracy: 88.2667%  Loss: 792.272278 (improved)\n",
      "Epoch: 70  Val accuracy: 88.6667%  Loss: 798.991821\n",
      "Epoch: 71  Val accuracy: 87.7333%  Loss: 800.366272\n",
      "Epoch: 72  Val accuracy: 88.6667%  Loss: 800.537109\n",
      "Epoch: 73  Val accuracy: 88.6667%  Loss: 794.455750\n",
      "Epoch: 74  Val accuracy: 86.4000%  Loss: 799.927612\n",
      "Epoch: 75  Val accuracy: 86.0000%  Loss: 798.627991\n",
      "Epoch: 76  Val accuracy: 85.0667%  Loss: 796.247864\n",
      "Epoch: 77  Val accuracy: 90.0000%  Loss: 800.126282\n",
      "Epoch: 78  Val accuracy: 88.4000%  Loss: 800.718811\n",
      "Epoch: 79  Val accuracy: 88.1333%  Loss: 794.519653\n",
      "Epoch: 80  Val accuracy: 89.2000%  Loss: 796.560608\n",
      "Epoch: 81  Val accuracy: 89.4667%  Loss: 797.261047\n",
      "Epoch: 82  Val accuracy: 89.3333%  Loss: 798.879089\n",
      "Epoch: 83  Val accuracy: 88.9333%  Loss: 796.409912\n",
      "Epoch: 84  Val accuracy: 88.2667%  Loss: 798.688660\n",
      "Epoch: 85  Val accuracy: 89.3333%  Loss: 797.611938\n",
      "Epoch: 86  Val accuracy: 88.9333%  Loss: 800.661255\n",
      "Epoch: 87  Val accuracy: 89.3333%  Loss: 799.362854\n",
      "Epoch: 88  Val accuracy: 89.3333%  Loss: 793.747925\n",
      "Epoch: 89  Val accuracy: 88.8000%  Loss: 795.848389\n",
      "Epoch: 90  Val accuracy: 90.4000%  Loss: 797.693909\n",
      "Epoch: 91  Val accuracy: 88.8000%  Loss: 792.642578\n",
      "Epoch: 92  Val accuracy: 89.4667%  Loss: 799.125122\n",
      "Epoch: 93  Val accuracy: 88.1333%  Loss: 796.898804\n",
      "Epoch: 94  Val accuracy: 86.5333%  Loss: 797.923218\n",
      "Epoch: 95  Val accuracy: 88.4000%  Loss: 796.383423\n",
      "Epoch: 96  Val accuracy: 88.0000%  Loss: 798.768982\n",
      "Epoch: 97  Val accuracy: 86.4000%  Loss: 795.092896\n",
      "Epoch: 98  Val accuracy: 89.3333%  Loss: 797.930115\n",
      "Epoch: 99  Val accuracy: 88.2667%  Loss: 801.661865\n",
      "Epoch: 100  Val accuracy: 88.6667%  Loss: 800.257996\n",
      "Epoch: 101  Val accuracy: 90.0000%  Loss: 795.556763\n",
      "Epoch: 102  Val accuracy: 88.5333%  Loss: 796.528015\n",
      "Epoch: 103  Val accuracy: 89.2000%  Loss: 796.952454\n",
      "Epoch: 104  Val accuracy: 88.8000%  Loss: 801.109253\n",
      "Epoch: 105  Val accuracy: 89.2000%  Loss: 796.890686\n",
      "Epoch: 106  Val accuracy: 89.3333%  Loss: 803.948486\n",
      "Epoch: 107  Val accuracy: 90.0000%  Loss: 801.247070\n",
      "Epoch: 108  Val accuracy: 89.2000%  Loss: 801.482361\n",
      "Epoch: 109  Val accuracy: 89.3333%  Loss: 798.790405\n",
      "Epoch: 110  Val accuracy: 89.0667%  Loss: 799.022339\n",
      "Epoch: 111  Val accuracy: 89.7333%  Loss: 796.501709\n",
      "Epoch: 112  Val accuracy: 89.4667%  Loss: 798.166931\n",
      "Epoch: 113  Val accuracy: 89.6000%  Loss: 795.636780\n",
      "Epoch: 114  Val accuracy: 89.3333%  Loss: 797.837219\n",
      "Epoch: 115  Val accuracy: 89.7333%  Loss: 797.760986\n",
      "Epoch: 116  Val accuracy: 89.4667%  Loss: 800.584717\n",
      "Epoch: 117  Val accuracy: 89.2000%  Loss: 800.870300\n",
      "Epoch: 118  Val accuracy: 89.4667%  Loss: 798.408447\n",
      "Epoch: 119  Val accuracy: 89.6000%  Loss: 797.319702\n",
      "Epoch: 120  Val accuracy: 89.4667%  Loss: 794.358643\n",
      "Epoch: 121  Val accuracy: 89.2000%  Loss: 798.154541\n",
      "Epoch: 122  Val accuracy: 89.3333%  Loss: 798.538086\n",
      "Epoch: 123  Val accuracy: 90.1333%  Loss: 799.602417\n",
      "Epoch: 124  Val accuracy: 89.7333%  Loss: 797.659851\n",
      "Epoch: 125  Val accuracy: 89.8667%  Loss: 797.275269\n",
      "Epoch: 126  Val accuracy: 89.8667%  Loss: 801.018677\n",
      "Epoch: 127  Val accuracy: 89.8667%  Loss: 796.728882\n",
      "Epoch: 128  Val accuracy: 90.0000%  Loss: 800.590393\n",
      "Epoch: 129  Val accuracy: 90.4000%  Loss: 800.402954\n",
      "Epoch: 130  Val accuracy: 89.6000%  Loss: 802.378540\n",
      "Epoch: 131  Val accuracy: 90.1333%  Loss: 797.184570\n",
      "Epoch: 132  Val accuracy: 89.8667%  Loss: 796.419067\n",
      "Epoch: 133  Val accuracy: 89.7333%  Loss: 798.232422\n",
      "Epoch: 134  Val accuracy: 90.0000%  Loss: 797.399292\n",
      "Epoch: 135  Val accuracy: 90.6667%  Loss: 801.334900\n",
      "Epoch: 136  Val accuracy: 90.0000%  Loss: 796.999939\n",
      "Epoch: 137  Val accuracy: 90.4000%  Loss: 799.818115\n",
      "Epoch: 138  Val accuracy: 90.0000%  Loss: 799.664429\n",
      "Epoch: 139  Val accuracy: 89.8667%  Loss: 803.103455\n",
      "Epoch: 140  Val accuracy: 90.0000%  Loss: 800.853577\n",
      "Epoch: 141  Val accuracy: 90.1333%  Loss: 800.616272\n",
      "Epoch: 142  Val accuracy: 90.2667%  Loss: 797.964172\n",
      "Epoch: 143  Val accuracy: 90.2667%  Loss: 800.357666\n",
      "Epoch: 144  Val accuracy: 89.4667%  Loss: 798.040100\n",
      "Epoch: 145  Val accuracy: 90.0000%  Loss: 799.853577\n",
      "Epoch: 146  Val accuracy: 89.8667%  Loss: 797.675903\n",
      "Epoch: 147  Val accuracy: 90.1333%  Loss: 799.429260\n",
      "Epoch: 148  Val accuracy: 90.0000%  Loss: 799.956970\n",
      "Epoch: 149  Val accuracy: 89.7333%  Loss: 798.022400\n",
      "Epoch: 150  Val accuracy: 89.8667%  Loss: 797.270081\n"
     ]
    }
   ],
   "source": [
    "# x_train[0:40].shape\n",
    "with tf.Session() as sess:\n",
    "#     if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "#         saver.restore(sess, checkpoint_path)\n",
    "#     else:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        x_train,y_train = shuffle(x_train,y_train)\n",
    "        x_test,y_test = shuffle(x_test,y_test)\n",
    "        for iteration in range(0, n_iterations_per_epoch):\n",
    "            X_batch = x_train[iteration * batch_size: (iteration * batch_size) + batch_size ]\n",
    "            y_batch = y_train[iteration * batch_size: (iteration * batch_size) + batch_size ]\n",
    "            \n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch,\n",
    "                           y: y_batch,\n",
    "                           mask_with_labels: True})\n",
    "            \n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "        \n",
    "        \n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        \n",
    "        for iteration in range(0, n_iterations_validation):\n",
    "            X_batch = x_test[iteration * batch_size: (iteration * batch_size) + batch_size ]\n",
    "            y_batch = y_test[iteration * batch_size: (iteration * batch_size) + batch_size ]\n",
    "            \n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch,\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            \n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "            \n",
    "            \n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "        if loss_val < best_loss_val:\n",
    "#             save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
