{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CapsNet\n",
    "\n",
    "This is the core algorithm of this thesis. It is based on [Dynamic Routing Between Capsules](https://arxiv.org/abs/1710.09829) paper by Sara Sabour, Nicholas Frosst and Geoffrey E. Hinton.\n",
    "\n",
    "I added few changes to [handson-ml](https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb)'s implementation. \n",
    "\n",
    "There is one big change from the original algorithm and it is primary casules' filter sizes. First 2 convolution layers has filter size of 9. In this thesis, we used a sattelite image and cut the picture with respect to coordinate system that is given. In our tests, 2 different image size and channel types are used. Sizes are 32x32 and 9x9. For 9x9 images, if we use filter size of 9, we got negative filter size thus for 9x9 images, filter size is droped to 3x3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# np.random.seed(42)\n",
    "# tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train =  get_data_set(\"train\",input_path = \"../input/data_9x9_13band/\")\n",
    "x_test,y_test = get_data_set(\"test\",input_path = \"../input/data_9x9_13band/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 9, 9, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, x_train.shape[1], x_train.shape[2], x_train.shape[3]], dtype=tf.float32, name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'X:0' shape=(?, 9, 9, 13) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primary Capsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size_conv1 = 3\n",
    "kernel_size_conv2 = 3\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 2\n",
    "img_size = x_test.shape[1]\n",
    "img_size = int(((img_size - kernel_size_conv1) / stride_conv1) + 1)\n",
    "img_size = int(((img_size - kernel_size_conv2) / stride_conv2) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps * img_size * img_size # * band_size\n",
    "caps1_n_dims = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", filters = 256,\n",
    "                        kernel_size = kernel_size_conv1, strides = stride_conv1,\n",
    "                        padding = \"valid\",activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv1/Relu:0' shape=(?, 7, 7, 256) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", filters = caps1_n_maps * caps1_n_dims,\n",
    "                        kernel_size = kernel_size_conv2, strides = stride_conv2,\n",
    "                        padding = \"valid\",activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2/Relu:0' shape=(?, 3, 3, 256) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_raw:0' shape=(?, 288, 8) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps1_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-fc0e932a5d7c>:5: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_output/mul:0' shape=(?, 288, 8) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15\n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\") \n",
    "caps1_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape = np.unique(y_train).shape[0]\n",
    "caps2_n_caps = output_shape\n",
    "caps2_n_dims = 16\n",
    "type(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'W_tiled:0' shape=(?, 288, 4, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_output_tiled:0' shape=(?, 288, 4, 8, 1) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps1_output_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_predicted:0' shape=(?, 288, 4, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routing by agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'raw_weights:0' shape=(?, 288, 4, 1, 1) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")\n",
    "raw_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-86a489ae595f>:1: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_1/mul:0' shape=(?, 1, 4, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_round_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_weights_round_2 = tf.add(raw_weights, agreement,\n",
    "                             name=\"raw_weights_round_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output = caps2_output_round_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 4, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimated Class Probabilities (Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_proba_1:0' shape=(?, 1, 1) dtype=int64>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "y_proba_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_pred:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 4, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'T:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tf.one_hot(y, depth=output_shape, name=\"T\")\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'present_error:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, output_shape),\n",
    "                           name=\"present_error\")\n",
    "present_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, output_shape),\n",
    "                          name=\"absent_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'L:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size :  404\n",
      "validation set size :  793\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 150\n",
    "batch_size = 15\n",
    "restore_checkpoint = True\n",
    "num_train_examples = x_train.shape[0]\n",
    "num_test_examples = x_test.shape[0]\n",
    "n_iterations_per_epoch = num_train_examples // batch_size\n",
    "n_iterations_validation = num_test_examples // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "\n",
    "print(\"training set size : \", num_train_examples)\n",
    "print(\"validation set size : \", num_test_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X,Y):\n",
    "    X_per = []\n",
    "    Y_per = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    for i in permutation:\n",
    "        X_per.append(X[i])\n",
    "        Y_per.append(Y[i])\n",
    "        \n",
    "    return np.array(X_per),np.array(Y_per)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 72.5641%  Loss: 0.215379 (improved)\n",
      "Epoch: 2  Val accuracy: 84.3590%  Loss: 0.120701 (improved)\n",
      "Epoch: 3  Val accuracy: 79.6154%  Loss: 0.134813\n",
      "Epoch: 4  Val accuracy: 85.6410%  Loss: 0.101840 (improved)\n",
      "Epoch: 5  Val accuracy: 87.6923%  Loss: 0.093770 (improved)\n",
      "Epoch: 6  Val accuracy: 78.5897%  Loss: 0.143587\n",
      "Epoch: 7  Val accuracy: 85.2564%  Loss: 0.103384\n",
      "Epoch: 8  Val accuracy: 80.5128%  Loss: 0.133410\n",
      "Epoch: 9  Val accuracy: 85.5128%  Loss: 0.096175\n",
      "Epoch: 10  Val accuracy: 87.1795%  Loss: 0.086118 (improved)\n",
      "Epoch: 11  Val accuracy: 86.2821%  Loss: 0.095586\n",
      "Epoch: 12  Val accuracy: 86.5385%  Loss: 0.092326\n",
      "Epoch: 13  Val accuracy: 86.6667%  Loss: 0.090499\n",
      "Epoch: 14  Val accuracy: 88.0769%  Loss: 0.094461\n",
      "Epoch: 15  Val accuracy: 89.2308%  Loss: 0.080076 (improved)\n",
      "Epoch: 16  Val accuracy: 86.5385%  Loss: 0.098274\n",
      "Epoch: 17  Val accuracy: 88.0769%  Loss: 0.087442\n",
      "Epoch: 18  Val accuracy: 85.5128%  Loss: 0.099029\n",
      "Epoch: 19  Val accuracy: 86.4102%  Loss: 0.096532\n",
      "Epoch: 20  Val accuracy: 82.5641%  Loss: 0.109444\n",
      "Epoch: 21  Val accuracy: 87.6923%  Loss: 0.086723\n",
      "Epoch: 22  Val accuracy: 85.5128%  Loss: 0.099236\n",
      "Epoch: 23  Val accuracy: 88.2051%  Loss: 0.079029 (improved)\n",
      "Epoch: 24  Val accuracy: 87.0513%  Loss: 0.091300\n",
      "Epoch: 25  Val accuracy: 86.9231%  Loss: 0.091431\n",
      "Epoch: 26  Val accuracy: 88.3333%  Loss: 0.082886\n",
      "Epoch: 27  Val accuracy: 84.3590%  Loss: 0.105920\n",
      "Epoch: 28  Val accuracy: 87.5641%  Loss: 0.089236\n",
      "Epoch: 29  Val accuracy: 84.3590%  Loss: 0.106830\n",
      "Epoch: 30  Val accuracy: 81.5385%  Loss: 0.124347\n",
      "Epoch: 31  Val accuracy: 88.3333%  Loss: 0.083063\n",
      "Epoch: 32  Val accuracy: 88.8461%  Loss: 0.087594\n",
      "Epoch: 33  Val accuracy: 87.8205%  Loss: 0.087497\n",
      "Epoch: 34  Val accuracy: 87.8205%  Loss: 0.093137\n",
      "Epoch: 35  Val accuracy: 88.2051%  Loss: 0.083572\n",
      "Epoch: 36  Val accuracy: 87.8205%  Loss: 0.124847\n",
      "Epoch: 37  Val accuracy: 84.6154%  Loss: 0.102305\n",
      "Epoch: 38  Val accuracy: 67.3077%  Loss: 0.216019\n",
      "Epoch: 39  Val accuracy: 84.4872%  Loss: 0.117128\n",
      "Epoch: 40  Val accuracy: 85.8974%  Loss: 0.105337\n",
      "Epoch: 41  Val accuracy: 82.9487%  Loss: 0.114537\n",
      "Epoch: 42  Val accuracy: 84.4872%  Loss: 0.123829\n",
      "Epoch: 43  Val accuracy: 87.9487%  Loss: 0.090173\n",
      "Epoch: 44  Val accuracy: 83.5897%  Loss: 0.110392\n",
      "Epoch: 45  Val accuracy: 76.0256%  Loss: 0.150114\n",
      "Epoch: 46  Val accuracy: 82.3077%  Loss: 0.115696\n",
      "Epoch: 47  Val accuracy: 87.1795%  Loss: 0.099127\n",
      "Epoch: 48  Val accuracy: 83.2051%  Loss: 0.110461\n",
      "Epoch: 49  Val accuracy: 88.4615%  Loss: 0.085065\n",
      "Epoch: 50  Val accuracy: 89.2308%  Loss: 0.085360\n",
      "Epoch: 51  Val accuracy: 87.5641%  Loss: 0.086913\n",
      "Epoch: 52  Val accuracy: 81.5385%  Loss: 0.110925\n",
      "Epoch: 53  Val accuracy: 86.7949%  Loss: 0.092336\n",
      "Epoch: 54  Val accuracy: 85.6410%  Loss: 0.098840\n",
      "Epoch: 55  Val accuracy: 87.9487%  Loss: 0.084937\n",
      "Epoch: 56  Val accuracy: 78.8461%  Loss: 0.124362\n",
      "Epoch: 57  Val accuracy: 85.6410%  Loss: 0.092551\n",
      "Epoch: 58  Val accuracy: 87.5641%  Loss: 0.091727\n",
      "Epoch: 59  Val accuracy: 88.0769%  Loss: 0.087063\n",
      "Epoch: 60  Val accuracy: 84.4872%  Loss: 0.115371\n",
      "Epoch: 61  Val accuracy: 87.6923%  Loss: 0.095036\n",
      "Epoch: 62  Val accuracy: 83.8462%  Loss: 0.106729\n",
      "Epoch: 63  Val accuracy: 86.4103%  Loss: 0.098100\n",
      "Epoch: 64  Val accuracy: 87.0513%  Loss: 0.087653\n",
      "Epoch: 65  Val accuracy: 84.8718%  Loss: 0.106996\n",
      "Epoch: 66  Val accuracy: 87.6923%  Loss: 0.084941\n",
      "Epoch: 67  Val accuracy: 85.8974%  Loss: 0.096296\n",
      "Epoch: 68  Val accuracy: 82.0513%  Loss: 0.116342\n",
      "Epoch: 69  Val accuracy: 86.6667%  Loss: 0.090529\n",
      "Epoch: 70  Val accuracy: 84.6154%  Loss: 0.107483\n",
      "Epoch: 71  Val accuracy: 86.4103%  Loss: 0.093963\n",
      "Epoch: 72  Val accuracy: 87.0513%  Loss: 0.094926\n",
      "Epoch: 73  Val accuracy: 88.0769%  Loss: 0.089594\n",
      "Epoch: 74  Val accuracy: 88.2051%  Loss: 0.091472\n",
      "Epoch: 75  Val accuracy: 86.4102%  Loss: 0.096540\n",
      "Epoch: 76  Val accuracy: 87.9487%  Loss: 0.091391\n",
      "Epoch: 77  Val accuracy: 86.5385%  Loss: 0.102252\n",
      "Epoch: 78  Val accuracy: 87.0513%  Loss: 0.091117\n",
      "Epoch: 79  Val accuracy: 85.0000%  Loss: 0.103691\n",
      "Epoch: 80  Val accuracy: 88.2051%  Loss: 0.089280\n",
      "Epoch: 81  Val accuracy: 85.1282%  Loss: 0.107554\n",
      "Epoch: 82  Val accuracy: 88.4615%  Loss: 0.089928\n",
      "Epoch: 83  Val accuracy: 86.2821%  Loss: 0.096373\n",
      "Epoch: 84  Val accuracy: 85.8974%  Loss: 0.099677\n",
      "Epoch: 85  Val accuracy: 86.4103%  Loss: 0.098141\n",
      "Epoch: 86  Val accuracy: 87.4359%  Loss: 0.093572\n",
      "Epoch: 87  Val accuracy: 85.8974%  Loss: 0.099516\n",
      "Epoch: 88  Val accuracy: 88.2051%  Loss: 0.089888\n",
      "Epoch: 89  Val accuracy: 87.9487%  Loss: 0.092380\n",
      "Epoch: 90  Val accuracy: 84.8718%  Loss: 0.100763\n",
      "Epoch: 91  Val accuracy: 86.7949%  Loss: 0.090657\n",
      "Epoch: 92  Val accuracy: 87.0513%  Loss: 0.095121\n",
      "Epoch: 93  Val accuracy: 87.8205%  Loss: 0.092963\n",
      "Epoch: 94  Val accuracy: 87.3077%  Loss: 0.087038\n",
      "Epoch: 95  Val accuracy: 87.3077%  Loss: 0.092508\n",
      "Epoch: 96  Val accuracy: 83.9744%  Loss: 0.122195\n",
      "Epoch: 97  Val accuracy: 86.5385%  Loss: 0.095622\n",
      "Epoch: 98  Val accuracy: 87.1795%  Loss: 0.091892\n",
      "Epoch: 99  Val accuracy: 86.0256%  Loss: 0.105848\n",
      "Epoch: 100  Val accuracy: 87.3077%  Loss: 0.095809\n",
      "Epoch: 101  Val accuracy: 87.4359%  Loss: 0.080302\n",
      "Epoch: 102  Val accuracy: 87.6923%  Loss: 0.088447\n",
      "Epoch: 103  Val accuracy: 85.1282%  Loss: 0.102382\n",
      "Epoch: 104  Val accuracy: 86.2821%  Loss: 0.094037\n",
      "Epoch: 105  Val accuracy: 87.9487%  Loss: 0.089962\n",
      "Epoch: 106  Val accuracy: 87.4359%  Loss: 0.086121\n",
      "Epoch: 107  Val accuracy: 88.4615%  Loss: 0.078786 (improved)\n",
      "Epoch: 108  Val accuracy: 86.2821%  Loss: 0.095104\n",
      "Epoch: 109  Val accuracy: 87.3077%  Loss: 0.090178\n",
      "Epoch: 110  Val accuracy: 87.8205%  Loss: 0.092539\n",
      "Epoch: 111  Val accuracy: 87.0513%  Loss: 0.095795\n",
      "Epoch: 112  Val accuracy: 88.3333%  Loss: 0.092728\n",
      "Epoch: 113  Val accuracy: 87.0513%  Loss: 0.089282\n",
      "Epoch: 114  Val accuracy: 85.5128%  Loss: 0.100687\n",
      "Epoch: 115  Val accuracy: 87.3077%  Loss: 0.100170\n",
      "Epoch: 116  Val accuracy: 87.5641%  Loss: 0.088962\n",
      "Epoch: 117  Val accuracy: 86.4103%  Loss: 0.096236\n",
      "Epoch: 118  Val accuracy: 86.2821%  Loss: 0.100770\n",
      "Epoch: 119  Val accuracy: 87.9487%  Loss: 0.095027\n",
      "Epoch: 120  Val accuracy: 88.2051%  Loss: 0.096840\n",
      "Epoch: 121  Val accuracy: 87.8205%  Loss: 0.094011\n",
      "Epoch: 122  Val accuracy: 84.7436%  Loss: 0.111934\n",
      "Epoch: 123  Val accuracy: 88.2051%  Loss: 0.088924\n",
      "Epoch: 124  Val accuracy: 88.3333%  Loss: 0.090763\n",
      "Epoch: 125  Val accuracy: 88.2051%  Loss: 0.090172\n",
      "Epoch: 126  Val accuracy: 88.5897%  Loss: 0.086917\n",
      "Epoch: 127  Val accuracy: 87.5641%  Loss: 0.084113\n",
      "Epoch: 128  Val accuracy: 87.5641%  Loss: 0.089154\n",
      "Epoch: 129  Val accuracy: 85.2564%  Loss: 0.110798\n",
      "Epoch: 130  Val accuracy: 88.2051%  Loss: 0.095174\n",
      "Epoch: 131  Val accuracy: 88.2051%  Loss: 0.090615\n",
      "Epoch: 132  Val accuracy: 87.8205%  Loss: 0.086142\n",
      "Epoch: 133  Val accuracy: 88.8462%  Loss: 0.083278\n",
      "Epoch: 134  Val accuracy: 88.8461%  Loss: 0.085847\n",
      "Epoch: 135  Val accuracy: 87.5641%  Loss: 0.089704\n",
      "Epoch: 136  Val accuracy: 87.6923%  Loss: 0.093646\n",
      "Epoch: 137  Val accuracy: 85.7692%  Loss: 0.103060\n",
      "Epoch: 138  Val accuracy: 84.2308%  Loss: 0.112212\n",
      "Epoch: 139  Val accuracy: 87.0513%  Loss: 0.123122\n",
      "Epoch: 140  Val accuracy: 88.4615%  Loss: 0.089580\n",
      "Epoch: 141  Val accuracy: 88.3333%  Loss: 0.084130\n",
      "Epoch: 142  Val accuracy: 87.5641%  Loss: 0.097988\n",
      "Epoch: 143  Val accuracy: 87.6923%  Loss: 0.098265\n",
      "Epoch: 144  Val accuracy: 86.4103%  Loss: 0.097112\n",
      "Epoch: 145  Val accuracy: 88.2051%  Loss: 0.087990\n",
      "Epoch: 146  Val accuracy: 88.5897%  Loss: 0.085114\n",
      "Epoch: 147  Val accuracy: 88.7180%  Loss: 0.087379\n",
      "Epoch: 148  Val accuracy: 88.5897%  Loss: 0.086355\n",
      "Epoch: 149  Val accuracy: 88.2051%  Loss: 0.087066\n",
      "Epoch: 150  Val accuracy: 87.4359%  Loss: 0.087141\n"
     ]
    }
   ],
   "source": [
    "# x_train[0:40].shape\n",
    "with tf.Session() as sess:\n",
    "#     if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "#         saver.restore(sess, checkpoint_path)\n",
    "#     else:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        x_train,y_train = shuffle(x_train,y_train)\n",
    "        x_test,y_test = shuffle(x_test,y_test)\n",
    "        for iteration in range(0, n_iterations_per_epoch):\n",
    "            X_batch = x_train[iteration * batch_size: (iteration * batch_size) + batch_size ]\n",
    "            y_batch = y_train[iteration * batch_size: (iteration * batch_size) + batch_size ]\n",
    "            \n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch,\n",
    "                           y: y_batch})\n",
    "            \n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "        \n",
    "        \n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        \n",
    "        for iteration in range(0, n_iterations_validation):\n",
    "            X_batch = x_test[iteration * batch_size: (iteration * batch_size) + batch_size ]\n",
    "            y_batch = y_test[iteration * batch_size: (iteration * batch_size) + batch_size ]\n",
    "            \n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch,\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            \n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "            \n",
    "            \n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "        if loss_val < best_loss_val:\n",
    "#             save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
