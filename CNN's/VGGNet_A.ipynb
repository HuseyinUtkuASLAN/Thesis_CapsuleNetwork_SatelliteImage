{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet_A\n",
    "\n",
    "VGG_A is the architecture with fewest amount of layers in VGGNet paper(link below)\n",
    "\n",
    "VGGNet uses small kernel sizes (uses 3 except in VGGNet_C's 7th, 10th and 13th convolution layers) and stride 1. \n",
    "\n",
    "More information can be found in [VERY DEEP CONVOLUTIONAL NETWORKS\n",
    "FOR LARGE-SCALE IMAGE RECOGNITION](https://arxiv.org/pdf/1409.1556.pdf) by Karen Simonyan& Andrew Zisserman.\n",
    "\n",
    "### Architecture\n",
    "input -> conv3-64 -> maxpool -> conv3-128 -> maxpool -> conv3-256 -> conv3-256 -> maxpool -> conv3-512 -> conv3-512 -> maxpool -> conv3-512 -> conv3-512 -> maxpool -> flatten -> fc4096 -> fc4096 -> output\n",
    "\n",
    "### Note :\n",
    "Because of the small image sizes, paddings are changed to \"SAME\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input\n",
    "from keras.layers import Activation\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "save_dir = \"./results\"\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "lr=0.001\n",
    "decay=0.0005\n",
    "momentum=0.9\n",
    "log_dir = \"./tensorboard/VGGNet_A_9x9_13x/\"\n",
    "# originals\n",
    "# save_dir = \"./results\"\n",
    "# batch_size = 50\n",
    "# epochs = 50\n",
    "# lr=0.01\n",
    "# decay=0.0005\n",
    "# momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 9, 9, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,Y_train = get_data_set(\"train\",input_path = \"../input/data_9x9_13band/\",one_hot = True)\n",
    "X_test,Y_test = get_data_set(\"test\",input_path = \"../input/data_9x9_13band/\", one_hot = True)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=log_dir,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 9, 9, 13) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(X_train.shape[1:])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1 = Convolution2D(64, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_1')(inputs)\n",
    "conv_1 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2 = Convolution2D(128, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_2')(conv_1)\n",
    "conv_2 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3 = Convolution2D(256, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_3')(conv_2)\n",
    "conv_4 = Convolution2D(256, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_4')(conv_3)\n",
    "conv_4 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_5 = Convolution2D(512, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_5')(conv_4)\n",
    "conv_6 = Convolution2D(512, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_6')(conv_5)\n",
    "conv_6 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_7 = Convolution2D(512, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_7')(conv_6)\n",
    "conv_8 = Convolution2D(512, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_8')(conv_7)\n",
    "conv_8 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_1 = Flatten(name='flatten')(conv_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'softmax/Softmax:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_1 = Dense(4096, activation='relu', name='dense_1')(dense_1)\n",
    "dense_2 = Dropout(0.5)(dense_1)\n",
    "dense_2 = Dense(4096, activation='relu', name='dense_2')(dense_2)\n",
    "dense_3 = Dropout(0.5)(dense_2)\n",
    "dense_3 = Dense(Y_train.shape[1], name='dense_3')(dense_3)\n",
    "prediction = Activation('softmax', name='softmax')(dense_3)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(outputs=prediction,inputs = inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "sgd = SGD(lr=lr, decay=decay, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 9, 9, 13)          0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 9, 9, 64)          7552      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv_8 (Conv2D)              (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 16388     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 28,125,188\n",
      "Trainable params: 28,125,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 793 samples\n",
      "Epoch 1/200\n",
      "404/404 [==============================] - 10s 24ms/step - loss: 1.5362 - acc: 0.3045 - val_loss: 1.4943 - val_acc: 0.0076\n",
      "Epoch 2/200\n",
      "404/404 [==============================] - 11s 27ms/step - loss: 1.2307 - acc: 0.4752 - val_loss: 0.7563 - val_acc: 0.8222\n",
      "Epoch 3/200\n",
      "404/404 [==============================] - 9s 23ms/step - loss: 0.8587 - acc: 0.6683 - val_loss: 1.1758 - val_acc: 0.4578\n",
      "Epoch 4/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.7283 - acc: 0.7277 - val_loss: 0.9368 - val_acc: 0.7251\n",
      "Epoch 5/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 0.6819 - acc: 0.7525 - val_loss: 0.6224 - val_acc: 0.7629\n",
      "Epoch 6/200\n",
      "404/404 [==============================] - 14s 34ms/step - loss: 0.5992 - acc: 0.7970 - val_loss: 0.5371 - val_acc: 0.8285\n",
      "Epoch 7/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 0.3446 - acc: 0.9059 - val_loss: 0.5606 - val_acc: 0.8285\n",
      "Epoch 8/200\n",
      "404/404 [==============================] - 11s 28ms/step - loss: 0.2330 - acc: 0.9257 - val_loss: 0.8001 - val_acc: 0.7654\n",
      "Epoch 9/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 0.2290 - acc: 0.9233 - val_loss: 0.4164 - val_acc: 0.8827\n",
      "Epoch 10/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.2088 - acc: 0.9282 - val_loss: 0.6623 - val_acc: 0.8197\n",
      "Epoch 11/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 0.1798 - acc: 0.9381 - val_loss: 0.5110 - val_acc: 0.8424\n",
      "Epoch 12/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 0.1762 - acc: 0.9455 - val_loss: 0.5313 - val_acc: 0.8588\n",
      "Epoch 13/200\n",
      "404/404 [==============================] - 12s 31ms/step - loss: 0.1272 - acc: 0.9604 - val_loss: 0.4173 - val_acc: 0.8752\n",
      "Epoch 14/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 0.0872 - acc: 0.9752 - val_loss: 0.4776 - val_acc: 0.8537\n",
      "Epoch 15/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 0.0890 - acc: 0.9703 - val_loss: 0.6112 - val_acc: 0.8197\n",
      "Epoch 16/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.0834 - acc: 0.9728 - val_loss: 0.6440 - val_acc: 0.8373\n",
      "Epoch 17/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.0681 - acc: 0.9802 - val_loss: 0.4487 - val_acc: 0.8689\n",
      "Epoch 18/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.1222 - acc: 0.9653 - val_loss: 0.4726 - val_acc: 0.8701\n",
      "Epoch 19/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 0.0634 - acc: 0.9777 - val_loss: 0.9357 - val_acc: 0.7743\n",
      "Epoch 20/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.1625 - acc: 0.9480 - val_loss: 0.6801 - val_acc: 0.8272\n",
      "Epoch 21/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 0.0800 - acc: 0.9678 - val_loss: 0.5918 - val_acc: 0.8411\n",
      "Epoch 22/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 0.0306 - acc: 0.9876 - val_loss: 0.5569 - val_acc: 0.8499\n",
      "Epoch 23/200\n",
      "404/404 [==============================] - 12s 31ms/step - loss: 0.0270 - acc: 0.9901 - val_loss: 0.5986 - val_acc: 0.8600\n",
      "Epoch 24/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 0.0208 - acc: 0.9926 - val_loss: 0.8191 - val_acc: 0.8285\n",
      "Epoch 25/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 0.0351 - acc: 0.9851 - val_loss: 0.9852 - val_acc: 0.8285\n",
      "Epoch 26/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 0.0454 - acc: 0.9827 - val_loss: 0.5771 - val_acc: 0.8726\n",
      "Epoch 27/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.0376 - acc: 0.9901 - val_loss: 0.7193 - val_acc: 0.8373\n",
      "Epoch 28/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 0.3354 - acc: 0.8985 - val_loss: 0.5633 - val_acc: 0.8537\n",
      "Epoch 29/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.1895 - acc: 0.9257 - val_loss: 0.7320 - val_acc: 0.7604\n",
      "Epoch 30/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 0.0905 - acc: 0.9678 - val_loss: 0.6067 - val_acc: 0.8487\n",
      "Epoch 31/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 0.0892 - acc: 0.9752 - val_loss: 0.7882 - val_acc: 0.8159\n",
      "Epoch 32/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 0.0832 - acc: 0.9802 - val_loss: 0.5739 - val_acc: 0.8323\n",
      "Epoch 33/200\n",
      "404/404 [==============================] - 12s 31ms/step - loss: 0.0221 - acc: 0.9950 - val_loss: 0.4918 - val_acc: 0.8689\n",
      "Epoch 34/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.7088 - val_acc: 0.8462\n",
      "Epoch 35/200\n",
      "404/404 [==============================] - 12s 31ms/step - loss: 0.0186 - acc: 0.9950 - val_loss: 0.7666 - val_acc: 0.8184\n",
      "Epoch 36/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.0427 - acc: 0.9851 - val_loss: 0.4990 - val_acc: 0.8726\n",
      "Epoch 37/200\n",
      "404/404 [==============================] - 11s 28ms/step - loss: 0.0160 - acc: 0.9975 - val_loss: 0.8479 - val_acc: 0.8235\n",
      "Epoch 38/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 0.0336 - acc: 0.9901 - val_loss: 0.6180 - val_acc: 0.8525\n",
      "Epoch 39/200\n",
      "404/404 [==============================] - 11s 26ms/step - loss: 0.0052 - acc: 0.9975 - val_loss: 0.5529 - val_acc: 0.8651\n",
      "Epoch 40/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5500 - val_acc: 0.8777\n",
      "Epoch 41/200\n",
      "404/404 [==============================] - 11s 28ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.6030 - val_acc: 0.8625\n",
      "Epoch 42/200\n",
      "404/404 [==============================] - 11s 27ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6517 - val_acc: 0.8689\n",
      "Epoch 43/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6326 - val_acc: 0.8764\n",
      "Epoch 44/200\n",
      "404/404 [==============================] - 11s 28ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6536 - val_acc: 0.8739\n",
      "Epoch 45/200\n",
      "404/404 [==============================] - 11s 28ms/step - loss: 8.3366e-04 - acc: 1.0000 - val_loss: 0.6726 - val_acc: 0.8689\n",
      "Epoch 46/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 6.9071e-04 - acc: 1.0000 - val_loss: 0.6764 - val_acc: 0.8701\n",
      "Epoch 47/200\n",
      "404/404 [==============================] - 11s 28ms/step - loss: 7.8135e-04 - acc: 1.0000 - val_loss: 0.6762 - val_acc: 0.8752\n",
      "Epoch 48/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 6.2633e-04 - acc: 1.0000 - val_loss: 0.6844 - val_acc: 0.8752\n",
      "Epoch 49/200\n",
      "404/404 [==============================] - 11s 28ms/step - loss: 5.1220e-04 - acc: 1.0000 - val_loss: 0.6972 - val_acc: 0.8701\n",
      "Epoch 50/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 6.9862e-04 - acc: 1.0000 - val_loss: 0.7019 - val_acc: 0.8689\n",
      "Epoch 51/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 4.4364e-04 - acc: 1.0000 - val_loss: 0.7060 - val_acc: 0.8663\n",
      "Epoch 52/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 6.2026e-04 - acc: 1.0000 - val_loss: 0.7037 - val_acc: 0.8739\n",
      "Epoch 53/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 4.0552e-04 - acc: 1.0000 - val_loss: 0.7096 - val_acc: 0.8726\n",
      "Epoch 54/200\n",
      "404/404 [==============================] - 12s 31ms/step - loss: 3.6887e-04 - acc: 1.0000 - val_loss: 0.7189 - val_acc: 0.8701\n",
      "Epoch 55/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 3.2025e-04 - acc: 1.0000 - val_loss: 0.7237 - val_acc: 0.8689\n",
      "Epoch 56/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 2.7142e-04 - acc: 1.0000 - val_loss: 0.7234 - val_acc: 0.8726\n",
      "Epoch 57/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 3.3212e-04 - acc: 1.0000 - val_loss: 0.7273 - val_acc: 0.8739\n",
      "Epoch 58/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 4.0304e-04 - acc: 1.0000 - val_loss: 0.7316 - val_acc: 0.8676\n",
      "Epoch 59/200\n",
      "404/404 [==============================] - 12s 31ms/step - loss: 3.2316e-04 - acc: 1.0000 - val_loss: 0.7318 - val_acc: 0.8701\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 13s 33ms/step - loss: 3.1269e-04 - acc: 1.0000 - val_loss: 0.7371 - val_acc: 0.8701\n",
      "Epoch 61/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 4.3481e-04 - acc: 1.0000 - val_loss: 0.7463 - val_acc: 0.8701\n",
      "Epoch 62/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 2.2870e-04 - acc: 1.0000 - val_loss: 0.7539 - val_acc: 0.8676\n",
      "Epoch 63/200\n",
      "404/404 [==============================] - 14s 34ms/step - loss: 2.4824e-04 - acc: 1.0000 - val_loss: 0.7593 - val_acc: 0.8651\n",
      "Epoch 64/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 2.8572e-04 - acc: 1.0000 - val_loss: 0.7580 - val_acc: 0.8689\n",
      "Epoch 65/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 2.4027e-04 - acc: 1.0000 - val_loss: 0.7601 - val_acc: 0.8689\n",
      "Epoch 66/200\n",
      "404/404 [==============================] - 14s 36ms/step - loss: 3.7876e-04 - acc: 1.0000 - val_loss: 0.7644 - val_acc: 0.8689\n",
      "Epoch 67/200\n",
      "404/404 [==============================] - 15s 38ms/step - loss: 2.3412e-04 - acc: 1.0000 - val_loss: 0.7687 - val_acc: 0.8689\n",
      "Epoch 68/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.8183e-04 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.8689\n",
      "Epoch 69/200\n",
      "404/404 [==============================] - 14s 34ms/step - loss: 2.3319e-04 - acc: 1.0000 - val_loss: 0.7691 - val_acc: 0.8726\n",
      "Epoch 70/200\n",
      "404/404 [==============================] - 16s 38ms/step - loss: 2.7139e-04 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.8726\n",
      "Epoch 71/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 2.7726e-04 - acc: 1.0000 - val_loss: 0.7739 - val_acc: 0.8701\n",
      "Epoch 72/200\n",
      "404/404 [==============================] - 11s 27ms/step - loss: 2.1370e-04 - acc: 1.0000 - val_loss: 0.7786 - val_acc: 0.8701\n",
      "Epoch 73/200\n",
      "404/404 [==============================] - 12s 29ms/step - loss: 1.4633e-04 - acc: 1.0000 - val_loss: 0.7805 - val_acc: 0.8701\n",
      "Epoch 74/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 1.8702e-04 - acc: 1.0000 - val_loss: 0.7837 - val_acc: 0.8689\n",
      "Epoch 75/200\n",
      "404/404 [==============================] - 14s 35ms/step - loss: 1.9668e-04 - acc: 1.0000 - val_loss: 0.7873 - val_acc: 0.8651\n",
      "Epoch 76/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 1.8519e-04 - acc: 1.0000 - val_loss: 0.7878 - val_acc: 0.8701\n",
      "Epoch 77/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 2.5934e-04 - acc: 1.0000 - val_loss: 0.7903 - val_acc: 0.8701\n",
      "Epoch 78/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.7880e-04 - acc: 1.0000 - val_loss: 0.7929 - val_acc: 0.8701\n",
      "Epoch 79/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 1.2037e-04 - acc: 1.0000 - val_loss: 0.7965 - val_acc: 0.8714\n",
      "Epoch 80/200\n",
      "404/404 [==============================] - 14s 35ms/step - loss: 3.2062e-04 - acc: 1.0000 - val_loss: 0.7974 - val_acc: 0.8663\n",
      "Epoch 81/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 1.7080e-04 - acc: 1.0000 - val_loss: 0.7950 - val_acc: 0.8663\n",
      "Epoch 82/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.9021e-04 - acc: 1.0000 - val_loss: 0.7926 - val_acc: 0.8689\n",
      "Epoch 83/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.9283e-04 - acc: 1.0000 - val_loss: 0.7921 - val_acc: 0.8714\n",
      "Epoch 84/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 3.0057e-04 - acc: 1.0000 - val_loss: 0.8006 - val_acc: 0.8714\n",
      "Epoch 85/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 2.7585e-04 - acc: 1.0000 - val_loss: 0.8048 - val_acc: 0.8714\n",
      "Epoch 86/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 1.8958e-04 - acc: 1.0000 - val_loss: 0.8016 - val_acc: 0.8676\n",
      "Epoch 87/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 1.9260e-04 - acc: 1.0000 - val_loss: 0.8026 - val_acc: 0.8676\n",
      "Epoch 88/200\n",
      "404/404 [==============================] - 14s 35ms/step - loss: 1.6437e-04 - acc: 1.0000 - val_loss: 0.8035 - val_acc: 0.8689\n",
      "Epoch 89/200\n",
      "404/404 [==============================] - 15s 38ms/step - loss: 1.4577e-04 - acc: 1.0000 - val_loss: 0.8052 - val_acc: 0.8689\n",
      "Epoch 90/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.3150e-04 - acc: 1.0000 - val_loss: 0.8071 - val_acc: 0.8701\n",
      "Epoch 91/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 1.6058e-04 - acc: 1.0000 - val_loss: 0.8083 - val_acc: 0.8701\n",
      "Epoch 92/200\n",
      "404/404 [==============================] - 12s 31ms/step - loss: 1.3858e-04 - acc: 1.0000 - val_loss: 0.8114 - val_acc: 0.8714\n",
      "Epoch 93/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.5872e-04 - acc: 1.0000 - val_loss: 0.8175 - val_acc: 0.8714\n",
      "Epoch 94/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.8347e-04 - acc: 1.0000 - val_loss: 0.8222 - val_acc: 0.8714\n",
      "Epoch 95/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 1.5559e-04 - acc: 1.0000 - val_loss: 0.8267 - val_acc: 0.8651\n",
      "Epoch 96/200\n",
      "404/404 [==============================] - 14s 34ms/step - loss: 1.3973e-04 - acc: 1.0000 - val_loss: 0.8244 - val_acc: 0.8689\n",
      "Epoch 97/200\n",
      "404/404 [==============================] - 15s 38ms/step - loss: 1.6326e-04 - acc: 1.0000 - val_loss: 0.8237 - val_acc: 0.8701\n",
      "Epoch 98/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.7850e-04 - acc: 1.0000 - val_loss: 0.8243 - val_acc: 0.8676\n",
      "Epoch 99/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 2.4094e-04 - acc: 1.0000 - val_loss: 0.8261 - val_acc: 0.8676\n",
      "Epoch 100/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 9.9616e-05 - acc: 1.0000 - val_loss: 0.8300 - val_acc: 0.8689\n",
      "Epoch 101/200\n",
      "404/404 [==============================] - 15s 36ms/step - loss: 8.8668e-05 - acc: 1.0000 - val_loss: 0.8315 - val_acc: 0.8689\n",
      "Epoch 102/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 1.0955e-04 - acc: 1.0000 - val_loss: 0.8334 - val_acc: 0.8714\n",
      "Epoch 103/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 1.2081e-04 - acc: 1.0000 - val_loss: 0.8335 - val_acc: 0.8701\n",
      "Epoch 104/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 2.4159e-04 - acc: 1.0000 - val_loss: 0.8292 - val_acc: 0.8701\n",
      "Epoch 105/200\n",
      "404/404 [==============================] - 12s 31ms/step - loss: 1.3712e-04 - acc: 1.0000 - val_loss: 0.8271 - val_acc: 0.8739\n",
      "Epoch 106/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.3808e-04 - acc: 1.0000 - val_loss: 0.8284 - val_acc: 0.8701\n",
      "Epoch 107/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.0722e-04 - acc: 1.0000 - val_loss: 0.8310 - val_acc: 0.8714\n",
      "Epoch 108/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 1.0761e-04 - acc: 1.0000 - val_loss: 0.8327 - val_acc: 0.8689\n",
      "Epoch 109/200\n",
      "404/404 [==============================] - 14s 36ms/step - loss: 1.5096e-04 - acc: 1.0000 - val_loss: 0.8368 - val_acc: 0.8676\n",
      "Epoch 110/200\n",
      "404/404 [==============================] - 15s 38ms/step - loss: 8.4854e-05 - acc: 1.0000 - val_loss: 0.8411 - val_acc: 0.8676\n",
      "Epoch 111/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 7.7293e-05 - acc: 1.0000 - val_loss: 0.8439 - val_acc: 0.8651\n",
      "Epoch 112/200\n",
      "404/404 [==============================] - 14s 34ms/step - loss: 1.0343e-04 - acc: 1.0000 - val_loss: 0.8421 - val_acc: 0.8676\n",
      "Epoch 113/200\n",
      "404/404 [==============================] - 16s 39ms/step - loss: 7.2700e-05 - acc: 1.0000 - val_loss: 0.8416 - val_acc: 0.8689\n",
      "Epoch 114/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 9.1269e-05 - acc: 1.0000 - val_loss: 0.8426 - val_acc: 0.8689\n",
      "Epoch 115/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 8.1539e-05 - acc: 1.0000 - val_loss: 0.8443 - val_acc: 0.8689\n",
      "Epoch 116/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.1775e-04 - acc: 1.0000 - val_loss: 0.8468 - val_acc: 0.8701\n",
      "Epoch 117/200\n",
      "404/404 [==============================] - 14s 34ms/step - loss: 1.1523e-04 - acc: 1.0000 - val_loss: 0.8485 - val_acc: 0.8714\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 15s 38ms/step - loss: 1.1622e-04 - acc: 1.0000 - val_loss: 0.8483 - val_acc: 0.8714\n",
      "Epoch 119/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.2438e-04 - acc: 1.0000 - val_loss: 0.8505 - val_acc: 0.8726\n",
      "Epoch 120/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 8.7130e-05 - acc: 1.0000 - val_loss: 0.8513 - val_acc: 0.8714\n",
      "Epoch 121/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 5.8674e-05 - acc: 1.0000 - val_loss: 0.8514 - val_acc: 0.8701\n",
      "Epoch 122/200\n",
      "404/404 [==============================] - 14s 35ms/step - loss: 8.6181e-05 - acc: 1.0000 - val_loss: 0.8519 - val_acc: 0.8689\n",
      "Epoch 123/200\n",
      "404/404 [==============================] - 15s 38ms/step - loss: 6.6961e-05 - acc: 1.0000 - val_loss: 0.8525 - val_acc: 0.8689\n",
      "Epoch 124/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 7.5198e-05 - acc: 1.0000 - val_loss: 0.8527 - val_acc: 0.8689\n",
      "Epoch 125/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 6.7225e-05 - acc: 1.0000 - val_loss: 0.8541 - val_acc: 0.8689\n",
      "Epoch 126/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 6.8370e-05 - acc: 1.0000 - val_loss: 0.8550 - val_acc: 0.8689\n",
      "Epoch 127/200\n",
      "404/404 [==============================] - 14s 36ms/step - loss: 7.7195e-05 - acc: 1.0000 - val_loss: 0.8550 - val_acc: 0.8689\n",
      "Epoch 128/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 6.1143e-05 - acc: 1.0000 - val_loss: 0.8566 - val_acc: 0.8701\n",
      "Epoch 129/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 9.9433e-05 - acc: 1.0000 - val_loss: 0.8578 - val_acc: 0.8701\n",
      "Epoch 130/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 7.9140e-05 - acc: 1.0000 - val_loss: 0.8593 - val_acc: 0.8689\n",
      "Epoch 131/200\n",
      "404/404 [==============================] - 12s 31ms/step - loss: 1.2459e-04 - acc: 1.0000 - val_loss: 0.8595 - val_acc: 0.8676\n",
      "Epoch 132/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 6.2960e-05 - acc: 1.0000 - val_loss: 0.8606 - val_acc: 0.8676\n",
      "Epoch 133/200\n",
      "404/404 [==============================] - 16s 40ms/step - loss: 2.3870e-04 - acc: 1.0000 - val_loss: 0.8715 - val_acc: 0.8663\n",
      "Epoch 134/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 1.4038e-04 - acc: 1.0000 - val_loss: 0.8763 - val_acc: 0.8663\n",
      "Epoch 135/200\n",
      "404/404 [==============================] - 14s 36ms/step - loss: 8.0849e-05 - acc: 1.0000 - val_loss: 0.8760 - val_acc: 0.8663\n",
      "Epoch 136/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 5.5097e-05 - acc: 1.0000 - val_loss: 0.8758 - val_acc: 0.8663\n",
      "Epoch 137/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 9.5560e-05 - acc: 1.0000 - val_loss: 0.8741 - val_acc: 0.8663\n",
      "Epoch 138/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 5.3665e-05 - acc: 1.0000 - val_loss: 0.8732 - val_acc: 0.8663\n",
      "Epoch 139/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 7.4031e-05 - acc: 1.0000 - val_loss: 0.8731 - val_acc: 0.8676\n",
      "Epoch 140/200\n",
      "404/404 [==============================] - 14s 34ms/step - loss: 1.1352e-04 - acc: 1.0000 - val_loss: 0.8725 - val_acc: 0.8676\n",
      "Epoch 141/200\n",
      "404/404 [==============================] - 15s 38ms/step - loss: 6.3808e-05 - acc: 1.0000 - val_loss: 0.8729 - val_acc: 0.8663\n",
      "Epoch 142/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 2.3038e-04 - acc: 1.0000 - val_loss: 0.8698 - val_acc: 0.8676\n",
      "Epoch 143/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 1.1206e-04 - acc: 1.0000 - val_loss: 0.8648 - val_acc: 0.8714\n",
      "Epoch 144/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 7.8125e-05 - acc: 1.0000 - val_loss: 0.8637 - val_acc: 0.8739\n",
      "Epoch 145/200\n",
      "404/404 [==============================] - 14s 35ms/step - loss: 1.0029e-04 - acc: 1.0000 - val_loss: 0.8655 - val_acc: 0.8701\n",
      "Epoch 146/200\n",
      "404/404 [==============================] - 15s 38ms/step - loss: 6.9824e-05 - acc: 1.0000 - val_loss: 0.8681 - val_acc: 0.8676\n",
      "Epoch 147/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 6.7234e-05 - acc: 1.0000 - val_loss: 0.8702 - val_acc: 0.8689\n",
      "Epoch 148/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 1.2179e-04 - acc: 1.0000 - val_loss: 0.8741 - val_acc: 0.8689\n",
      "Epoch 149/200\n",
      "404/404 [==============================] - 13s 31ms/step - loss: 9.2795e-05 - acc: 1.0000 - val_loss: 0.8753 - val_acc: 0.8701\n",
      "Epoch 150/200\n",
      "404/404 [==============================] - 15s 36ms/step - loss: 6.0642e-05 - acc: 1.0000 - val_loss: 0.8765 - val_acc: 0.8689\n",
      "Epoch 151/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 5.8135e-05 - acc: 1.0000 - val_loss: 0.8781 - val_acc: 0.8701\n",
      "Epoch 152/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 6.7936e-05 - acc: 1.0000 - val_loss: 0.8790 - val_acc: 0.8676\n",
      "Epoch 153/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 5.9852e-05 - acc: 1.0000 - val_loss: 0.8806 - val_acc: 0.8676\n",
      "Epoch 154/200\n",
      "404/404 [==============================] - 12s 30ms/step - loss: 5.3915e-05 - acc: 1.0000 - val_loss: 0.8819 - val_acc: 0.8676\n",
      "Epoch 155/200\n",
      "404/404 [==============================] - 14s 36ms/step - loss: 7.2036e-05 - acc: 1.0000 - val_loss: 0.8824 - val_acc: 0.8676\n",
      "Epoch 156/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 6.9812e-05 - acc: 1.0000 - val_loss: 0.8818 - val_acc: 0.8689\n",
      "Epoch 157/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 6.1052e-05 - acc: 1.0000 - val_loss: 0.8810 - val_acc: 0.8689\n",
      "Epoch 158/200\n",
      "404/404 [==============================] - 14s 34ms/step - loss: 4.3757e-05 - acc: 1.0000 - val_loss: 0.8815 - val_acc: 0.8701\n",
      "Epoch 159/200\n",
      "404/404 [==============================] - 12s 31ms/step - loss: 8.7546e-05 - acc: 1.0000 - val_loss: 0.8839 - val_acc: 0.8676\n",
      "Epoch 160/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 9.2728e-05 - acc: 1.0000 - val_loss: 0.8848 - val_acc: 0.8676\n",
      "Epoch 161/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 6.5821e-05 - acc: 1.0000 - val_loss: 0.8833 - val_acc: 0.8676\n",
      "Epoch 162/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 9.1023e-05 - acc: 1.0000 - val_loss: 0.8827 - val_acc: 0.8663\n",
      "Epoch 163/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 8.1611e-05 - acc: 1.0000 - val_loss: 0.8825 - val_acc: 0.8663\n",
      "Epoch 164/200\n",
      "404/404 [==============================] - 15s 38ms/step - loss: 4.4255e-05 - acc: 1.0000 - val_loss: 0.8819 - val_acc: 0.8676\n",
      "Epoch 165/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 5.4777e-05 - acc: 1.0000 - val_loss: 0.8811 - val_acc: 0.8676\n",
      "Epoch 166/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 5.6964e-05 - acc: 1.0000 - val_loss: 0.8809 - val_acc: 0.8676\n",
      "Epoch 167/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 4.7568e-05 - acc: 1.0000 - val_loss: 0.8815 - val_acc: 0.8676\n",
      "Epoch 168/200\n",
      "404/404 [==============================] - 13s 33ms/step - loss: 8.1231e-05 - acc: 1.0000 - val_loss: 0.8806 - val_acc: 0.8676\n",
      "Epoch 169/200\n",
      "404/404 [==============================] - 16s 39ms/step - loss: 7.6101e-05 - acc: 1.0000 - val_loss: 0.8818 - val_acc: 0.8676\n",
      "Epoch 170/200\n",
      "404/404 [==============================] - 14s 35ms/step - loss: 6.2704e-05 - acc: 1.0000 - val_loss: 0.8832 - val_acc: 0.8689\n",
      "Epoch 171/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 8.8011e-05 - acc: 1.0000 - val_loss: 0.8847 - val_acc: 0.8689\n",
      "Epoch 172/200\n",
      "404/404 [==============================] - 13s 32ms/step - loss: 5.5376e-05 - acc: 1.0000 - val_loss: 0.8855 - val_acc: 0.8689\n",
      "Epoch 173/200\n",
      "384/404 [===========================>..] - ETA: 0s - loss: 7.0410e-05 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "model.fit(x = X_train, y = Y_train, batch_size=batch_size, epochs=epochs,\n",
    "              validation_data=[X_test,Y_test],shuffle = True,\n",
    "              callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
