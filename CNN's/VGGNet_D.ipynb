{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet_D or VGG16\n",
    "\n",
    "VGG_D is commonly known as VGG16 is considered to be a \"very deep network\" due to having 16 trainable layer.\n",
    "\n",
    "VGGNet uses small kernel sizes (uses 3 except in VGGNet_C's 7th, 10th and 13th convolution layers) and stride 1. \n",
    "\n",
    "More information can be found in [VERY DEEP CONVOLUTIONAL NETWORKS\n",
    "FOR LARGE-SCALE IMAGE RECOGNITION](https://arxiv.org/pdf/1409.1556.pdf) by Karen Simonyan& Andrew Zisserman.\n",
    "\n",
    "### Architecture\n",
    "input -> conv3-64 -> conv3-64 -> maxpool -> conv3-128 -> conv3-128 -> maxpool -> conv3-256 -> conv3-256 -> conv3-256 -> maxpool -> conv3-512 -> conv3-512 -> conv3-512 -> maxpool -> conv3-512 -> conv3-512 -> conv3-512 -> maxpool -> flatten -> fc4096 -> fc4096 -> output\n",
    "\n",
    "### Note :\n",
    "Because of the small image sizes, paddings are changed to \"SAME\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input\n",
    "from keras.layers import Activation\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "save_dir = \"./results\"\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "lr=0.001\n",
    "decay=0.0000\n",
    "momentum=0.9\n",
    "log_dir = \"./tensorboard/VGGNet_D_9x9_13/\"\n",
    "# originals\n",
    "# save_dir = \"./results\"\n",
    "# batch_size = 50\n",
    "# epochs = 50\n",
    "# lr=0.01\n",
    "# decay=0.0005\n",
    "# momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 9, 9, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,Y_train = get_data_set(\"train\",input_path = \"../input/data_9x9_13band/\",one_hot = True)\n",
    "X_test,Y_test = get_data_set(\"test\",input_path = \"../input/data_9x9_13band/\", one_hot = True)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=log_dir,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 9, 9, 13) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(X_train.shape[1:])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1 = Convolution2D(64, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_1')(inputs)\n",
    "conv_2 = Convolution2D(64, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_2')(conv_1)\n",
    "conv_2 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3 = Convolution2D(128, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_3')(conv_2)\n",
    "conv_4 = Convolution2D(128, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_4')(conv_3)\n",
    "conv_4 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_5 = Convolution2D(256, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_5')(conv_4)\n",
    "conv_6 = Convolution2D(256, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_6')(conv_5)\n",
    "conv_7 = Convolution2D(256, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_7')(conv_6)\n",
    "conv_7 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_8 = Convolution2D(512, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_8')(conv_7)\n",
    "conv_9 = Convolution2D(512, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_9')(conv_8)\n",
    "conv_10 = Convolution2D(512, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_10')(conv_9)\n",
    "conv_10 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_11 = Convolution2D(512, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_11')(conv_10)\n",
    "conv_12 = Convolution2D(512, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_12')(conv_11)\n",
    "conv_13 = Convolution2D(512, kernel_size =(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                           name='conv_13')(conv_12)\n",
    "conv_13 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_1 = Flatten(name='flatten')(conv_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'softmax/Softmax:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_1 = Dense(4096, activation='relu', name='dense_1')(dense_1)\n",
    "dense_2 = Dropout(0.5)(dense_1)\n",
    "dense_2 = Dense(4096, activation='relu', name='dense_2')(dense_2)\n",
    "dense_3 = Dropout(0.5)(dense_2)\n",
    "dense_3 = Dense(Y_train.shape[1], name='dense_3')(dense_3)\n",
    "prediction = Activation('softmax', name='softmax')(dense_3)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(outputs=prediction,inputs = inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "sgd = SGD(lr=lr, decay=decay, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 9, 9, 13)          0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 9, 9, 64)          7552      \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_8 (Conv2D)              (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv_9 (Conv2D)              (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv_10 (Conv2D)             (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_11 (Conv2D)             (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv_12 (Conv2D)             (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv_13 (Conv2D)             (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 16388     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 33,619,396\n",
      "Trainable params: 33,619,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 793 samples\n",
      "Epoch 1/200\n",
      "404/404 [==============================] - 16s 40ms/step - loss: 1.3859 - acc: 0.2228 - val_loss: 1.3744 - val_acc: 0.3884\n",
      "Epoch 2/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 1.3801 - acc: 0.2896 - val_loss: 1.3612 - val_acc: 0.3884\n",
      "Epoch 3/200\n",
      "404/404 [==============================] - 16s 41ms/step - loss: 1.3731 - acc: 0.3490 - val_loss: 1.3423 - val_acc: 0.6393\n",
      "Epoch 4/200\n",
      "404/404 [==============================] - 20s 49ms/step - loss: 1.3623 - acc: 0.3416 - val_loss: 1.3104 - val_acc: 0.6910\n",
      "Epoch 5/200\n",
      "404/404 [==============================] - 19s 48ms/step - loss: 1.3434 - acc: 0.3837 - val_loss: 1.2553 - val_acc: 0.7112\n",
      "Epoch 6/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 1.3210 - acc: 0.3267 - val_loss: 1.1721 - val_acc: 0.3808\n",
      "Epoch 7/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 1.2838 - acc: 0.3564 - val_loss: 1.1126 - val_acc: 0.6898\n",
      "Epoch 8/200\n",
      "404/404 [==============================] - 19s 47ms/step - loss: 1.2246 - acc: 0.4356 - val_loss: 0.9882 - val_acc: 0.6974\n",
      "Epoch 9/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 1.1055 - acc: 0.4802 - val_loss: 0.8200 - val_acc: 0.6444\n",
      "Epoch 10/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 1.0005 - acc: 0.5371 - val_loss: 1.1113 - val_acc: 0.5763\n",
      "Epoch 11/200\n",
      "404/404 [==============================] - 20s 50ms/step - loss: 1.0112 - acc: 0.5421 - val_loss: 0.6760 - val_acc: 0.7100\n",
      "Epoch 12/200\n",
      "404/404 [==============================] - 22s 55ms/step - loss: 0.8500 - acc: 0.6609 - val_loss: 0.9840 - val_acc: 0.6885\n",
      "Epoch 13/200\n",
      "404/404 [==============================] - 20s 49ms/step - loss: 0.8395 - acc: 0.7277 - val_loss: 0.6023 - val_acc: 0.7478\n",
      "Epoch 14/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.7627 - acc: 0.7748 - val_loss: 0.8177 - val_acc: 0.6419\n",
      "Epoch 15/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.7357 - acc: 0.7772 - val_loss: 0.7456 - val_acc: 0.7718\n",
      "Epoch 16/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 1.0207 - acc: 0.6733 - val_loss: 1.1558 - val_acc: 0.5637\n",
      "Epoch 17/200\n",
      "404/404 [==============================] - 18s 46ms/step - loss: 1.0560 - acc: 0.5545 - val_loss: 1.1578 - val_acc: 0.4199\n",
      "Epoch 18/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 0.8875 - acc: 0.6485 - val_loss: 0.7703 - val_acc: 0.7692\n",
      "Epoch 19/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.4910 - acc: 0.8515 - val_loss: 0.6068 - val_acc: 0.8121\n",
      "Epoch 20/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.3680 - acc: 0.8861 - val_loss: 0.4617 - val_acc: 0.8487\n",
      "Epoch 21/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.3236 - acc: 0.9035 - val_loss: 0.4906 - val_acc: 0.8209\n",
      "Epoch 22/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.2511 - acc: 0.9307 - val_loss: 0.5268 - val_acc: 0.8222\n",
      "Epoch 23/200\n",
      "404/404 [==============================] - 18s 46ms/step - loss: 0.6279 - acc: 0.8045 - val_loss: 1.1770 - val_acc: 0.5334\n",
      "Epoch 24/200\n",
      "404/404 [==============================] - 18s 44ms/step - loss: 0.9841 - acc: 0.5594 - val_loss: 0.8159 - val_acc: 0.5435\n",
      "Epoch 25/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.6660 - acc: 0.6955 - val_loss: 0.6856 - val_acc: 0.7137\n",
      "Epoch 26/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.5522 - acc: 0.7401 - val_loss: 0.6358 - val_acc: 0.7427\n",
      "Epoch 27/200\n",
      "404/404 [==============================] - 18s 44ms/step - loss: 0.4915 - acc: 0.8267 - val_loss: 0.6931 - val_acc: 0.7377\n",
      "Epoch 28/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.3544 - acc: 0.8787 - val_loss: 0.4346 - val_acc: 0.8562\n",
      "Epoch 29/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.2842 - acc: 0.8960 - val_loss: 0.8671 - val_acc: 0.7818\n",
      "Epoch 30/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.4432 - acc: 0.8614 - val_loss: 0.9661 - val_acc: 0.6936\n",
      "Epoch 31/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.2553 - acc: 0.9381 - val_loss: 0.4851 - val_acc: 0.8335\n",
      "Epoch 32/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.1749 - acc: 0.9356 - val_loss: 0.4906 - val_acc: 0.8525\n",
      "Epoch 33/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.1950 - acc: 0.9480 - val_loss: 0.6227 - val_acc: 0.8083\n",
      "Epoch 34/200\n",
      "404/404 [==============================] - 18s 44ms/step - loss: 0.1669 - acc: 0.9307 - val_loss: 0.4186 - val_acc: 0.8499\n",
      "Epoch 35/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.1246 - acc: 0.9678 - val_loss: 0.6729 - val_acc: 0.7995\n",
      "Epoch 36/200\n",
      "404/404 [==============================] - 18s 44ms/step - loss: 0.1734 - acc: 0.9406 - val_loss: 0.4415 - val_acc: 0.8537\n",
      "Epoch 37/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.1390 - acc: 0.9480 - val_loss: 0.8054 - val_acc: 0.8045\n",
      "Epoch 38/200\n",
      "404/404 [==============================] - 19s 46ms/step - loss: 0.1011 - acc: 0.9703 - val_loss: 0.5819 - val_acc: 0.8235\n",
      "Epoch 39/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 0.0972 - acc: 0.9579 - val_loss: 0.6818 - val_acc: 0.8159\n",
      "Epoch 40/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0898 - acc: 0.9554 - val_loss: 0.6305 - val_acc: 0.8525\n",
      "Epoch 41/200\n",
      "404/404 [==============================] - 18s 44ms/step - loss: 0.0987 - acc: 0.9703 - val_loss: 0.7466 - val_acc: 0.8096\n",
      "Epoch 42/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.1040 - acc: 0.9728 - val_loss: 0.4622 - val_acc: 0.8575\n",
      "Epoch 43/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.0914 - acc: 0.9678 - val_loss: 0.5808 - val_acc: 0.8449\n",
      "Epoch 44/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 0.0706 - acc: 0.9802 - val_loss: 0.8834 - val_acc: 0.7844\n",
      "Epoch 45/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 0.1413 - acc: 0.9653 - val_loss: 0.5245 - val_acc: 0.8235\n",
      "Epoch 46/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.0766 - acc: 0.9802 - val_loss: 0.4539 - val_acc: 0.8651\n",
      "Epoch 47/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.0670 - acc: 0.9703 - val_loss: 0.6358 - val_acc: 0.8335\n",
      "Epoch 48/200\n",
      "404/404 [==============================] - 19s 47ms/step - loss: 0.0561 - acc: 0.9827 - val_loss: 0.4957 - val_acc: 0.8701\n",
      "Epoch 49/200\n",
      "404/404 [==============================] - 18s 43ms/step - loss: 0.0540 - acc: 0.9802 - val_loss: 0.5661 - val_acc: 0.8525\n",
      "Epoch 50/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 0.0353 - acc: 0.9851 - val_loss: 0.5640 - val_acc: 0.8588\n",
      "Epoch 51/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0568 - acc: 0.9777 - val_loss: 0.6927 - val_acc: 0.8285\n",
      "Epoch 52/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0479 - acc: 0.9827 - val_loss: 0.6562 - val_acc: 0.8310\n",
      "Epoch 53/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.1265 - acc: 0.9629 - val_loss: 2.1344 - val_acc: 0.5612\n",
      "Epoch 54/200\n",
      "404/404 [==============================] - 16s 40ms/step - loss: 0.8338 - acc: 0.6881 - val_loss: 0.6721 - val_acc: 0.7201\n",
      "Epoch 55/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.4557 - acc: 0.8243 - val_loss: 0.6901 - val_acc: 0.7629\n",
      "Epoch 56/200\n",
      "404/404 [==============================] - 18s 43ms/step - loss: 0.2278 - acc: 0.9406 - val_loss: 0.4527 - val_acc: 0.8550\n",
      "Epoch 57/200\n",
      "404/404 [==============================] - 16s 39ms/step - loss: 0.1211 - acc: 0.9604 - val_loss: 0.5796 - val_acc: 0.8411\n",
      "Epoch 58/200\n",
      "404/404 [==============================] - 19s 47ms/step - loss: 0.0895 - acc: 0.9678 - val_loss: 0.4729 - val_acc: 0.8625\n",
      "Epoch 59/200\n",
      "404/404 [==============================] - 18s 44ms/step - loss: 0.1108 - acc: 0.9604 - val_loss: 0.5289 - val_acc: 0.8310\n",
      "Epoch 60/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 0.0585 - acc: 0.9851 - val_loss: 0.7043 - val_acc: 0.8373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.0485 - acc: 0.9901 - val_loss: 0.5404 - val_acc: 0.8562\n",
      "Epoch 62/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.0319 - acc: 0.9876 - val_loss: 0.5593 - val_acc: 0.8575\n",
      "Epoch 63/200\n",
      "404/404 [==============================] - 18s 43ms/step - loss: 0.0340 - acc: 0.9851 - val_loss: 0.6333 - val_acc: 0.8474\n",
      "Epoch 64/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0613 - acc: 0.9777 - val_loss: 0.6766 - val_acc: 0.8562\n",
      "Epoch 65/200\n",
      "404/404 [==============================] - 18s 44ms/step - loss: 0.0418 - acc: 0.9901 - val_loss: 0.6282 - val_acc: 0.8525\n",
      "Epoch 66/200\n",
      "404/404 [==============================] - 20s 49ms/step - loss: 0.0123 - acc: 0.9975 - val_loss: 0.6080 - val_acc: 0.8436\n",
      "Epoch 67/200\n",
      "404/404 [==============================] - 19s 47ms/step - loss: 0.0223 - acc: 0.9901 - val_loss: 0.6156 - val_acc: 0.8537\n",
      "Epoch 68/200\n",
      "404/404 [==============================] - 20s 50ms/step - loss: 0.0180 - acc: 0.9950 - val_loss: 0.6587 - val_acc: 0.8600\n",
      "Epoch 69/200\n",
      "404/404 [==============================] - 19s 46ms/step - loss: 0.0238 - acc: 0.9950 - val_loss: 0.5553 - val_acc: 0.8752\n",
      "Epoch 70/200\n",
      "404/404 [==============================] - 19s 48ms/step - loss: 0.0303 - acc: 0.9926 - val_loss: 0.5774 - val_acc: 0.8663\n",
      "Epoch 71/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0202 - acc: 0.9901 - val_loss: 0.6278 - val_acc: 0.8613\n",
      "Epoch 72/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0985 - acc: 0.9728 - val_loss: 1.2081 - val_acc: 0.7516\n",
      "Epoch 73/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.2858 - acc: 0.9257 - val_loss: 0.7888 - val_acc: 0.7667\n",
      "Epoch 74/200\n",
      "404/404 [==============================] - 15s 38ms/step - loss: 0.1087 - acc: 0.9728 - val_loss: 0.4501 - val_acc: 0.8789\n",
      "Epoch 75/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0560 - acc: 0.9802 - val_loss: 0.5132 - val_acc: 0.8600\n",
      "Epoch 76/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0336 - acc: 0.9926 - val_loss: 0.6180 - val_acc: 0.8373\n",
      "Epoch 77/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 0.0388 - acc: 0.9901 - val_loss: 0.5084 - val_acc: 0.8651\n",
      "Epoch 78/200\n",
      "404/404 [==============================] - 18s 45ms/step - loss: 0.0795 - acc: 0.9777 - val_loss: 1.0237 - val_acc: 0.7692\n",
      "Epoch 79/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0640 - acc: 0.9777 - val_loss: 0.6066 - val_acc: 0.8512\n",
      "Epoch 80/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0930 - acc: 0.9653 - val_loss: 0.4699 - val_acc: 0.8600\n",
      "Epoch 81/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0282 - acc: 0.9975 - val_loss: 0.4587 - val_acc: 0.8676\n",
      "Epoch 82/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0133 - acc: 0.9975 - val_loss: 0.5391 - val_acc: 0.8562\n",
      "Epoch 83/200\n",
      "404/404 [==============================] - 16s 39ms/step - loss: 0.0284 - acc: 0.9926 - val_loss: 0.6080 - val_acc: 0.8550\n",
      "Epoch 84/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0170 - acc: 0.9926 - val_loss: 0.5776 - val_acc: 0.8701\n",
      "Epoch 85/200\n",
      "404/404 [==============================] - 15s 37ms/step - loss: 0.0122 - acc: 0.9950 - val_loss: 0.5735 - val_acc: 0.8701\n",
      "Epoch 86/200\n",
      "404/404 [==============================] - 18s 44ms/step - loss: 0.0746 - acc: 0.9827 - val_loss: 0.7121 - val_acc: 0.8348\n",
      "Epoch 87/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0620 - acc: 0.9802 - val_loss: 0.9027 - val_acc: 0.7579\n",
      "Epoch 88/200\n",
      "404/404 [==============================] - 14s 35ms/step - loss: 0.0910 - acc: 0.9703 - val_loss: 0.5178 - val_acc: 0.8499\n",
      "Epoch 89/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0628 - acc: 0.9802 - val_loss: 0.5058 - val_acc: 0.8625\n",
      "Epoch 90/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.5030 - val_acc: 0.8714\n",
      "Epoch 91/200\n",
      "404/404 [==============================] - 18s 44ms/step - loss: 0.0196 - acc: 0.9950 - val_loss: 0.5054 - val_acc: 0.8739\n",
      "Epoch 92/200\n",
      "404/404 [==============================] - 19s 46ms/step - loss: 0.0125 - acc: 0.9950 - val_loss: 0.5734 - val_acc: 0.8613\n",
      "Epoch 93/200\n",
      "404/404 [==============================] - 17s 43ms/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.8044 - val_acc: 0.8209\n",
      "Epoch 94/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0307 - acc: 0.9876 - val_loss: 0.8122 - val_acc: 0.8235\n",
      "Epoch 95/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0205 - acc: 0.9950 - val_loss: 0.8096 - val_acc: 0.8298\n",
      "Epoch 96/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.6708 - val_acc: 0.8625\n",
      "Epoch 97/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.6697 - val_acc: 0.8638\n",
      "Epoch 98/200\n",
      "404/404 [==============================] - 15s 38ms/step - loss: 0.0138 - acc: 0.9950 - val_loss: 0.7502 - val_acc: 0.8575\n",
      "Epoch 99/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0199 - acc: 0.9926 - val_loss: 0.6833 - val_acc: 0.8600\n",
      "Epoch 100/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0141 - acc: 0.9950 - val_loss: 0.7305 - val_acc: 0.8588\n",
      "Epoch 101/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0050 - acc: 0.9975 - val_loss: 0.7143 - val_acc: 0.8625\n",
      "Epoch 102/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0034 - acc: 0.9975 - val_loss: 0.7304 - val_acc: 0.8714\n",
      "Epoch 103/200\n",
      "404/404 [==============================] - 17s 41ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7215 - val_acc: 0.8714\n",
      "Epoch 104/200\n",
      "404/404 [==============================] - 14s 34ms/step - loss: 9.4917e-04 - acc: 1.0000 - val_loss: 0.7499 - val_acc: 0.8588\n",
      "Epoch 105/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.8676\n",
      "Epoch 106/200\n",
      "404/404 [==============================] - 17s 42ms/step - loss: 0.0068 - acc: 0.9975 - val_loss: 0.7940 - val_acc: 0.8575\n",
      "Epoch 107/200\n",
      " 32/404 [=>............................] - ETA: 12s - loss: 4.0719e-04 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "model.fit(x = X_train, y = Y_train, batch_size=batch_size, epochs=epochs,\n",
    "              validation_data=[X_test,Y_test],shuffle = True,\n",
    "              callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
